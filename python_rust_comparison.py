#!/usr/bin/env python3
"""Python LightGBMã¨Rust LightGBMã®å‡ºåŠ›å€¤å·®åˆ†ã®è©³ç´°åˆ†æ"""

import lightgbm as lgb
import numpy as np
import subprocess
import json
import sys
import os
from pathlib import Path

def create_comprehensive_test_datasets():
    """åŒ…æ‹¬çš„ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ"""
    datasets = {}
    
    # Dataset 1: åŸºæœ¬çš„ãªãƒã‚¤ãƒŠãƒªåˆ†é¡ãƒ‡ãƒ¼ã‚¿
    np.random.seed(42)
    features1 = np.array([
        [1.0, 2.0, 0.5], [2.0, 1.0, 1.0], [3.0, 0.5, 2.0], [0.5, 3.0, 0.2],
        [2.5, 1.5, 1.2], [1.5, 2.5, 0.8], [3.2, 0.8, 1.8], [0.8, 2.8, 0.5],
        [2.0, 2.0, 1.0], [1.0, 1.0, 1.5], [3.5, 1.2, 2.2], [1.2, 3.2, 0.3],
        [2.8, 1.8, 1.5], [1.8, 2.2, 1.1], [3.0, 1.0, 2.0], [1.0, 3.0, 0.8]
    ], dtype=np.float32)
    labels1 = ((features1[:, 0] + features1[:, 1] - features1[:, 2]) > 2.0).astype(np.float32)
    datasets['binary_basic'] = (features1, labels1, 'binary')
    
    # Dataset 2: å›å¸°ãƒ‡ãƒ¼ã‚¿
    features2 = np.array([
        [1.0, 2.0, 0.5], [2.0, 1.0, 1.0], [3.0, 0.5, 2.0], [0.5, 3.0, 0.2],
        [2.5, 1.5, 1.2], [1.5, 2.5, 0.8], [3.2, 0.8, 1.8], [0.8, 2.8, 0.5],
        [2.0, 2.0, 1.0], [1.0, 1.0, 1.5]
    ], dtype=np.float32)
    labels2 = np.array([
        2.0 * features2[i, 0] + 3.0 * features2[i, 1] - features2[i, 2] + (i * 0.1)
        for i in range(len(features2))
    ], dtype=np.float32)
    datasets['regression'] = (features2, labels2, 'regression')
    
    # Dataset 3: ç•°ãªã‚‹ã‚¹ã‚±ãƒ¼ãƒ«ã®ãƒã‚¤ãƒŠãƒªåˆ†é¡
    features3 = np.array([
        [10.0, 20.0, 5.0], [20.0, 10.0, 10.0], [30.0, 5.0, 20.0], [5.0, 30.0, 2.0],
        [25.0, 15.0, 12.0], [15.0, 25.0, 8.0], [32.0, 8.0, 18.0], [8.0, 28.0, 5.0]
    ], dtype=np.float32)
    labels3 = ((features3[:, 0] + features3[:, 1] - features3[:, 2]) > 30.0).astype(np.float32)
    datasets['binary_scaled'] = (features3, labels3, 'binary')
    
    return datasets

def train_python_lightgbm(features, labels, objective_type):
    """Python LightGBMã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´"""
    if objective_type == 'binary':
        params = {
            'objective': 'binary',
            'metric': 'binary_logloss',
            'num_iterations': 10,
            'learning_rate': 0.1,
            'num_leaves': 7,
            'min_data_in_leaf': 1,
            'lambda_l2': 0.1,
            'verbose': -1,
            'seed': 42,
        }
    else:  # regression
        params = {
            'objective': 'regression',
            'metric': 'l2',
            'num_iterations': 10,
            'learning_rate': 0.1,
            'num_leaves': 7,
            'min_data_in_leaf': 1,
            'lambda_l2': 0.1,
            'verbose': -1,
            'seed': 42,
        }
    
    train_data = lgb.Dataset(features, label=labels)
    model = lgb.train(params, train_data)
    predictions = model.predict(features)
    
    return predictions

def create_rust_test_program(datasets):
    """Rustãƒ†ã‚¹ãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ä½œæˆ"""
    rust_code = '''//! Python vs Rust LightGBMæ¯”è¼ƒãƒ†ã‚¹ãƒˆ
use lightgbm_rust::*;
use ndarray::{Array1, Array2};
use serde_json;
use std::collections::HashMap;

fn main() -> Result<()> {
    lightgbm_rust::init()?;
    
    let mut results = HashMap::new();
    
'''
    
    for dataset_name, (features, labels, objective_type) in datasets.items():
        if objective_type == 'binary':
            objective_enum = 'ObjectiveType::Binary'
        else:
            objective_enum = 'ObjectiveType::Regression'
            
        rust_code += f'''
    // {dataset_name} dataset
    let features_{dataset_name} = Array2::from_shape_vec(
        ({features.shape[0]}, {features.shape[1]}),
        vec!{features.flatten().tolist()}
    ).expect("ç‰¹å¾´é‡é…åˆ—ã®ä½œæˆã«å¤±æ•—");
    
    let labels_{dataset_name} = Array1::from_vec(vec!{labels.tolist()});
    
    let dataset_{dataset_name} = Dataset::new(
        features_{dataset_name}.clone(), 
        labels_{dataset_name}, 
        None, None, None, None
    )?;
    
    let config_{dataset_name} = ConfigBuilder::new()
        .objective({objective_enum})
        .num_iterations(10)
        .learning_rate(0.1)
        .num_leaves(7)
        .min_data_in_leaf(1)
        .lambda_l2(0.1)
        .build()?;
    
    let mut gbdt_{dataset_name} = GBDT::new(config_{dataset_name}, dataset_{dataset_name})?;
    gbdt_{dataset_name}.train()?;
    
    let predictions_{dataset_name} = gbdt_{dataset_name}.predict(&features_{dataset_name})?;
    
    results.insert("{dataset_name}", serde_json::json!({{
        "predictions": predictions_{dataset_name},
        "objective": "{objective_type}"
    }}));
'''
    
    rust_code += '''
    
    println!("{}", serde_json::to_string_pretty(&results).unwrap());
    
    Ok(())
}'''
    
    return rust_code

def run_rust_test(rust_code):
    """Rustãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
    test_file = Path("src/bin/comparison_full.rs")
    
    try:
        test_file.parent.mkdir(exist_ok=True)
        
        with open(test_file, 'w') as f:
            f.write(rust_code)
        
        # ãƒ“ãƒ«ãƒ‰
        build_result = subprocess.run(
            ["cargo", "build", "--bin", "comparison_full"],
            capture_output=True,
            text=True
        )
        
        if build_result.returncode != 0:
            print(f"âŒ ãƒ“ãƒ«ãƒ‰ã‚¨ãƒ©ãƒ¼: {build_result.stderr}")
            return None
        
        # å®Ÿè¡Œ
        run_result = subprocess.run(
            ["cargo", "run", "--bin", "comparison_full"],
            capture_output=True,
            text=True
        )
        
        if run_result.returncode == 0:
            try:
                return json.loads(run_result.stdout)
            except json.JSONDecodeError:
                print(f"âŒ JSONè§£æå¤±æ•—: {run_result.stdout}")
                return None
        else:
            print(f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {run_result.stderr}")
            return None
            
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    finally:
        if test_file.exists():
            test_file.unlink()

def analyze_differences(py_pred, rust_pred, dataset_name, objective_type):
    """äºˆæ¸¬å€¤ã®å·®ç•°ã‚’è©³ç´°åˆ†æ"""
    py_array = np.array(py_pred)
    
    if isinstance(rust_pred, dict) and 'data' in rust_pred:
        rust_array = np.array(rust_pred['data'])
    else:
        rust_array = np.array(rust_pred)
    
    # åŸºæœ¬çµ±è¨ˆ
    abs_diff = np.abs(py_array - rust_array)
    rel_diff = np.abs((py_array - rust_array) / (py_array + 1e-10))  # ç›¸å¯¾èª¤å·®ï¼ˆã‚¼ãƒ­é™¤ç®—å›é¿ï¼‰
    
    stats = {
        'max_absolute_diff': float(np.max(abs_diff)),
        'mean_absolute_diff': float(np.mean(abs_diff)),
        'median_absolute_diff': float(np.median(abs_diff)),
        'std_absolute_diff': float(np.std(abs_diff)),
        'max_relative_diff': float(np.max(rel_diff)) * 100,  # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆ
        'mean_relative_diff': float(np.mean(rel_diff)) * 100,
        'rmse': float(np.sqrt(np.mean((py_array - rust_array) ** 2))),
        'python_range': [float(np.min(py_array)), float(np.max(py_array))],
        'rust_range': [float(np.min(rust_array)), float(np.max(rust_array))],
        'correlation': float(np.corrcoef(py_array, rust_array)[0, 1]) if len(py_array) > 1 else 1.0
    }
    
    return stats

def main():
    """ãƒ¡ã‚¤ãƒ³æ¯”è¼ƒåˆ†æ"""
    print("ğŸ” Python LightGBM vs Rust LightGBM è©³ç´°å·®åˆ†åˆ†æ")
    print("=" * 60)
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
    datasets = create_comprehensive_test_datasets()
    print(f"ğŸ“Š {len(datasets)}å€‹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æ¯”è¼ƒãƒ†ã‚¹ãƒˆ")
    
    # Python LightGBMã§å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å®Ÿè¡Œ
    print("\nğŸ Python LightGBMã§äºˆæ¸¬å®Ÿè¡Œä¸­...")
    python_results = {}
    for dataset_name, (features, labels, objective_type) in datasets.items():
        print(f"  - {dataset_name} ({objective_type})")
        python_results[dataset_name] = {
            'predictions': train_python_lightgbm(features, labels, objective_type),
            'objective': objective_type
        }
    
    # Rustãƒ†ã‚¹ãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ä½œæˆãƒ»å®Ÿè¡Œ
    print("\nğŸ¦€ Rust LightGBMã§äºˆæ¸¬å®Ÿè¡Œä¸­...")
    rust_code = create_rust_test_program(datasets)
    rust_results = run_rust_test(rust_code)
    
    if not rust_results:
        print("âŒ Rustãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    # è©³ç´°åˆ†æ
    print("\nğŸ“ˆ **è©³ç´°å·®åˆ†åˆ†æçµæœ**")
    print("=" * 60)
    
    overall_stats = {
        'max_diffs': [],
        'mean_diffs': [],
        'correlations': []
    }
    
    for dataset_name in datasets.keys():
        print(f"\nğŸ¯ **{dataset_name.upper()}** ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ:")
        
        py_pred = python_results[dataset_name]['predictions']
        rust_pred = rust_results[dataset_name]['predictions']
        objective_type = python_results[dataset_name]['objective']
        
        stats = analyze_differences(py_pred, rust_pred, dataset_name, objective_type)
        
        print(f"  ğŸ“Š åŸºæœ¬çµ±è¨ˆ:")
        print(f"    æœ€å¤§çµ¶å¯¾å·®:     {stats['max_absolute_diff']:.8e}")
        print(f"    å¹³å‡çµ¶å¯¾å·®:     {stats['mean_absolute_diff']:.8e}")
        print(f"    ä¸­å¤®å€¤çµ¶å¯¾å·®:   {stats['median_absolute_diff']:.8e}")
        print(f"    æ¨™æº–åå·®:       {stats['std_absolute_diff']:.8e}")
        print(f"    RMSE:          {stats['rmse']:.8e}")
        
        print(f"  ğŸ“ˆ ç›¸å¯¾èª¤å·®:")
        print(f"    æœ€å¤§ç›¸å¯¾å·®:     {stats['max_relative_diff']:.6f}%")
        print(f"    å¹³å‡ç›¸å¯¾å·®:     {stats['mean_relative_diff']:.6f}%")
        
        print(f"  ğŸ¯ äºˆæ¸¬å€¤ç¯„å›²:")
        print(f"    Python:        [{stats['python_range'][0]:.6f}, {stats['python_range'][1]:.6f}]")
        print(f"    Rust:          [{stats['rust_range'][0]:.6f}, {stats['rust_range'][1]:.6f}]")
        print(f"    ç›¸é–¢ä¿‚æ•°:       {stats['correlation']:.8f}")
        
        # ç²¾åº¦è©•ä¾¡
        if stats['max_absolute_diff'] < 1e-10:
            precision_level = "ğŸ‰ æ¥µã‚ã¦é«˜ç²¾åº¦ (< 1e-10)"
        elif stats['max_absolute_diff'] < 1e-8:
            precision_level = "âœ… éå¸¸ã«é«˜ç²¾åº¦ (< 1e-8)"
        elif stats['max_absolute_diff'] < 1e-6:
            precision_level = "âœ… é«˜ç²¾åº¦ (< 1e-6)"
        elif stats['max_absolute_diff'] < 1e-4:
            precision_level = "âš ï¸  ä¸­ç¨‹åº¦ã®ç²¾åº¦ (< 1e-4)"
        else:
            precision_level = "âŒ ä½ç²¾åº¦ (>= 1e-4)"
        
        print(f"  ğŸ† ç²¾åº¦è©•ä¾¡:      {precision_level}")
        
        # çµ±è¨ˆåé›†
        overall_stats['max_diffs'].append(stats['max_absolute_diff'])
        overall_stats['mean_diffs'].append(stats['mean_absolute_diff'])
        overall_stats['correlations'].append(stats['correlation'])
    
    # å…¨ä½“ç·æ‹¬
    print(f"\nğŸ† **å…¨ä½“ç·æ‹¬**")
    print(f"=" * 60)
    print(f"å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸­ã®:")
    print(f"  æœ€å¤§ã®æœ€å¤§çµ¶å¯¾å·®:   {max(overall_stats['max_diffs']):.8e}")
    print(f"  æœ€å°ã®æœ€å¤§çµ¶å¯¾å·®:   {min(overall_stats['max_diffs']):.8e}")
    print(f"  å¹³å‡ã®æœ€å¤§çµ¶å¯¾å·®:   {np.mean(overall_stats['max_diffs']):.8e}")
    print(f"  å¹³å‡ç›¸é–¢ä¿‚æ•°:       {np.mean(overall_stats['correlations']):.8f}")
    
    # æœ€çµ‚è©•ä¾¡
    max_overall_diff = max(overall_stats['max_diffs'])
    min_correlation = min(overall_stats['correlations'])
    
    if max_overall_diff < 1e-8 and min_correlation > 0.999:
        final_grade = "ğŸ‰ **å„ªç§€** - Python LightGBMã¨ã»ã¼åŒç­‰ã®ç²¾åº¦"
    elif max_overall_diff < 1e-6 and min_correlation > 0.99:
        final_grade = "âœ… **è‰¯å¥½** - å®Ÿç”¨çš„ãªç²¾åº¦ãƒ¬ãƒ™ãƒ«"
    elif max_overall_diff < 1e-4:
        final_grade = "âš ï¸  **æ”¹å–„ã®ä½™åœ°ã‚ã‚Š** - ä¸­ç¨‹åº¦ã®å·®ç•°"
    else:
        final_grade = "âŒ **è¦æ”¹å–„** - å¤§ããªå·®ç•°ã‚ã‚Š"
    
    print(f"\nğŸ¯ **æœ€çµ‚è©•ä¾¡**: {final_grade}")
    
    return max_overall_diff

if __name__ == "__main__":
    max_diff = main()
    if max_diff < 1e-6:
        print(f"\nâœ… **çµè«–**: Rustå®Ÿè£…ã¯é«˜ç²¾åº¦ (æœ€å¤§å·®ç•° {max_diff:.2e})")
    else:
        print(f"\nâš ï¸  **çµè«–**: æ”¹å–„ã®ä½™åœ°ã‚ã‚Š (æœ€å¤§å·®ç•° {max_diff:.2e})")